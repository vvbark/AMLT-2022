{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e762220-8cdb-4abc-b117-51fc10512cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "from torch import optim\n",
    "from adabelief_pytorch import AdaBelief\n",
    "from ACProp import ACProp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e3d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        return np.load(file)\n",
    "    \n",
    "def prepare_spectra(spectra, seed=2022):\n",
    "    # normalization\n",
    "    spectra = (spectra - spectra.min()) / (spectra.max() - spectra.min())\n",
    "    # permutation\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.permutation(spectra.shape[0])\n",
    "    spectra = spectra[idx]\n",
    "    \n",
    "    return spectra\n",
    "\n",
    "def prepare_params(params):\n",
    "    params = np.reshape(params, (params.shape[0], -1))\n",
    "    return params\n",
    "    \n",
    "def split_data(X, y, val_size=0.2):\n",
    "    idx_slice = int(X.shape[0] * val_size)\n",
    "    X_train, X_test = X[idx_slice:], X[:idx_slice]\n",
    "    y_train, y_test = y[idx_slice:], y[:idx_slice]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def make_loader(inputs, targets, batch_size=256):\n",
    "    loader = data.DataLoader(list(zip(inputs, targets)), batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581a0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = read_npy('spectrums.npy')\n",
    "params = read_npy('parameters.npy')\n",
    "\n",
    "spectra = prepare_spectra(spectra)\n",
    "params = prepare_params(params)\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(spectra, params, 0.1)\n",
    "\n",
    "train_loader = make_loader(X_train, y_train)\n",
    "test_loader = make_loader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc15418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(150, 100)\n",
    "        self.fc2 = nn.Linear(100, 75)\n",
    "        self.fc3 = nn.Linear(75, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f253d",
   "metadata": {},
   "source": [
    "## fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a625212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, optimizer, loss_function, train_loader, test_loader, epochs=50):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in (list(range(epochs))):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for idx, (inputs, targets) in enumerate(train_loader): \n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append((train_loss / (idx + 1)))\n",
    "\n",
    "        test_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (inputs, targets) in enumerate(test_loader):\n",
    "                inputs, targets = inputs.float(), targets.float()\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "        test_losses.append(test_loss / (idx + 1))\n",
    "        \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e71a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_grid = np.array([1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a5f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9310ab378f24fa184d8b921d8d2ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Weight decoupling enabled in AdaBelief\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "train_losses_grid = []\n",
    "test_losses_grid = []\n",
    "\n",
    "optimizers = [\n",
    "    AdaBelief(\n",
    "        net.parameters(),\n",
    "        lr=1e-4,\n",
    "        eps=1e-16,\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decouple=False,\n",
    "        rectify=False,\n",
    "        print_change_log=False,\n",
    "    ),\n",
    "    ACProp(\n",
    "        net.parameters(),\n",
    "        lr=lr,\n",
    "        eps=1e-8,\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decouple=True,\n",
    "        weight_decay=1e-4,\n",
    "        rectify=False,\n",
    "    ),\n",
    "]\n",
    "\n",
    "for lr, optimizer in tqdm(zip(learning_rate_grid, optimizers)):\n",
    "    net = Net()\n",
    "    train_losses, test_losses = fit_model(\n",
    "        model=net,\n",
    "        optimizer=optimizer,\n",
    "        loss_function=loss_function,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        epochs=50,\n",
    "    )\n",
    "    train_losses_grid.append(train_losses)\n",
    "    test_losses_grid.append(test_losses)\n",
    "    \n",
    "    with open(f'test_losses_grid_{optimizer.__class__.__name__}.npy', 'wb') as file:\n",
    "        np.save(file, np.array(test_losses_grid))\n",
    "        \n",
    "    with open(f'train_losses_grid_{optimizer.__class__.__name__}.npy', 'wb') as file:\n",
    "        np.save(file, np.array(test_losses_grid))\n",
    "        \n",
    "with open(f'learning_rate_grid.npy', 'wb') as file:\n",
    "    np.save(file, np.array(learning_rate_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba6738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
